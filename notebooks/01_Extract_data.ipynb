{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tweepy as tw\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key=\"KngwG7xjI9d02XVD0HwRWJsf4\"\n",
    "\n",
    "consumer_secret=\"xn9umFPHEZxbYZYucZgqVRPHlVjMmJxn2zyz3pM8Ly2TDz8LWu\"\n",
    "\n",
    "access_token=\"91827016-zAjwr3eUqmzDwStjwK3MD0gjTDRt3vJpFxgvGF3M5\"\n",
    "\n",
    "access_token_secret=\"bAKY8bF3XW9kEoc7N96BZFkDiV8gXm1CMhyP7Pa3X70WO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the authentication object\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret)\n",
    "# Setting your access token and secret\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "# Creating the API object while passing in auth information\n",
    "api = tw.API(auth,wait_on_rate_limit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#isme dekh lena koi keyword add krna ho to\n",
    "\n",
    "keywords_india=[\"Modi\",'BJP','Government','economy','GDP','corona','covid']\n",
    "\n",
    "keywords_turkey=[\"Erdoğan\",'AKP','hükümet','ekonomi','GSYİH','corona','covid']\n",
    "\n",
    "keywords_germany=[\"Merkel\",'CDP','Regierung','Wirtschaft','BIP','corona','covid']\n",
    "\n",
    "\n",
    "#geocodes are defined by latitude, longitude and radius to get tweets for a specific location\n",
    "\n",
    "\n",
    "geocodes_india={'28.7041,77.1025,30km':'Delhi','19.0760,72.8777,30km':'Mumbai',\n",
    "                '13.0827,80.2707,30km':'Chennai','22.5726,88.3639,30km':'Kolkata'}\n",
    "\n",
    "\n",
    "geocodes_turkey={'41.0082,28.9784,30km':'Istanbul','39.9334,32.8597,30km':'Ankara',\n",
    "                '38.4237,27.1428,30km':'Izmir','36.8969,30.7133,30km':'Antalya'}\n",
    "\n",
    "\n",
    "geocodes_germany={'52.5200,13.4050,30km':'Berlin','48.1351,11.5820,30km':'Munich',\n",
    "                '50.9375,6.9603,30km':'Cologne','53.5511,9.9937,30km':'Hamburg'}\n",
    "\n",
    "\n",
    "\n",
    "num_tweets= 1000   # Ye number of tweets hain. is number ko dekh lena change krke\n",
    "\n",
    "#ye get_tweets function hai jisme keywords, geocode aur num_tweets daalenge to tweets ki list milegi\n",
    "\n",
    "def get_tweets(keywords,geocodes,num_tweets):\n",
    "    Data_set={}\n",
    "    Data_set['Tweets']=[]\n",
    "    Data_set['Timestamp']=[]\n",
    "    Data_set['Location']=[]\n",
    "    Data_set['Keyword']=[]\n",
    "    for keyword in keywords:\n",
    "        for geo_code in geocodes.keys():\n",
    "            query=tw.Cursor(api.search,q=keyword,geocode=geo_code).items(num_tweets)\n",
    "            for tweet in query:\n",
    "                if (not tweet.retweeted) and ('RT @' not in tweet.text):\n",
    "                    Data_set['Tweets'].append(tweet.text)\n",
    "                    Data_set['Timestamp'].append(tweet.created_at)\n",
    "                    Data_set['Location'].append(geocodes[geo_code])\n",
    "                    Data_set['Keyword'].append(keyword)\n",
    "\n",
    "    return Data_set\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_india=get_tweets(keywords_india,geocodes_india,num_tweets) \n",
    "\n",
    "df_india=pd.DataFrame(tweets_india)  \n",
    "df_india.head()\n",
    "\n",
    "df_india.to_csv('.\\India_dataset_2.csv',encoding='utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_turkey=get_tweets(keywords_turkey,geocodes_turkey,num_tweets) \n",
    "\n",
    "df_turkey=pd.DataFrame(tweets_turkey)  \n",
    "\n",
    "df_turkey.to_csv('.\\Turkey_dataset_2.csv',encoding='utf-8')\n",
    "\n",
    "df_turkey.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(400)\n",
    "\n",
    "tweets_germany=get_tweets(keywords_germany,geocodes_germany,num_tweets) \n",
    "\n",
    "df_germany=pd.DataFrame(tweets_germany) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_germany.to_csv('.\\Germany_dataset_2.csv',encoding='utf-8')\n",
    "\n",
    "df_germany.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

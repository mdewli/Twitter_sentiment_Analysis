{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In this file we will work with the generated CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import string\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use pretrained BERT based transformer models to analyse the sentiment in three languages:\n",
    "English, Turkish and German\n",
    "\n",
    "The pretrained models can be installed via following commands:\n",
    "\n",
    "pip install transformers\n",
    "git lfs install\n",
    "git clone https://huggingface.co/oliverguhr/german-sentiment-bert\n",
    "git clone https://huggingface.co/savasy/bert-base-turkish-sentiment-cased\n",
    "\n",
    "Read documentation here: \n",
    "\n",
    "https://huggingface.co/transformers/quicktour.html\n",
    "https://huggingface.co/savasy/bert-base-turkish-sentiment-cased#\n",
    "https://huggingface.co/oliverguhr/german-sentiment-bert?text=I+like+you.+I+love+you#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model for sentiment analysis in turkish language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'positive', 'score': 0.983146607875824}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer_tr = AutoTokenizer.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "\n",
    "model_tr = AutoModelForSequenceClassification.from_pretrained(\"savasy/bert-base-turkish-sentiment-cased\")\n",
    "\n",
    "turkish= pipeline(\"sentiment-analysis\", tokenizer=tokenizer_tr, model=model_tr)\n",
    "\n",
    "#example\n",
    "\n",
    "t = turkish(\"bu telefon modelleri çok kaliteli , her parçası çok özel bence\")\n",
    "print(t)\n",
    "# [{'label': 'LABEL_1', 'score': 0.9871089}]\n",
    "# print(p[0]['label'] == 'LABEL_1')\n",
    "# True\n",
    "t[0]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model in english language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.999866783618927}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english = pipeline('sentiment-analysis')\n",
    "\n",
    "#example\n",
    "e=english(\"Hey, you are beautiful\")\n",
    "\n",
    "e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model in german language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9846150875091553"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tokenizer_gr = AutoTokenizer.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "model_gr = AutoModelForSequenceClassification.from_pretrained(\"oliverguhr/german-sentiment-bert\")\n",
    "\n",
    "german= pipeline(\"sentiment-analysis\", tokenizer=tokenizer_gr, model=model_gr)\n",
    "\n",
    "#example\n",
    "\n",
    "g=german(\"Ich liebe dich\")\n",
    "\n",
    "g[0]['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define functions to get sentiment and scores for turkish english and german languages.\n",
    "We will apply these functions to our pandas dataframes using \"df.apply(function)\"\" method\n",
    "\n",
    "Here 'sentiment_tr' and 'sentiment_score_tr' refer to the funtions that returns the sentiment (Positive/Negative) \n",
    "and the score (0-1) for a text in turkish language.\n",
    "\n",
    "Similarly we have defined functions to return the sentiment and scores for text in english and german.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sentiment_tr(sentence):\n",
    "    sentiment=turkish(sentence)[0]['label']\n",
    "    return sentiment\n",
    "\n",
    "def sentiment_score_tr(sentence):\n",
    "    score=turkish(sentence)[0]['score']\n",
    "    return score\n",
    "\n",
    "\n",
    "def sentiment_gr(sentence):\n",
    "    sentiment=german(sentence)[0]['label']\n",
    "    return sentiment\n",
    "\n",
    "def sentiment_score_gr(sentence):\n",
    "    score=german(sentence)[0]['score']\n",
    "    return score\n",
    "\n",
    "\n",
    "def sentiment_en(sentence):\n",
    "    sentiment=english(sentence)[0]['label']\n",
    "    return sentiment\n",
    "\n",
    "def sentiment_score_en(sentence):\n",
    "    score=english(sentence)[0]['score']\n",
    "    return score\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now download the stopwods in English, Turkish and German from spacy\n",
    "\n",
    "We will add some more stopwords from hindi and create a list of stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords. We chose stopwords from spacy because it has more stopwords than nltk and also has turkish stopwords\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords_english\n",
    "from spacy.lang.de.stop_words import STOP_WORDS as stopwords_deutsch\n",
    "from spacy.lang.tr.stop_words import STOP_WORDS as stopwords_turkish\n",
    "\n",
    "with open('data/hindi_stopwords.txt',encoding='utf-8') as file:  \n",
    "    line=file.read()\n",
    "    \n",
    "\n",
    "stopwords_hindi=line.split()\n",
    "\n",
    "more_stopwords=['erdoÄŸan','merkel','modi','bjp','cdp','akp','hÃ¼kÃ¼met','gsyä°h','government','govt','regierung','wirtschaft',\n",
    "                'corona','covid','economy','ekonomi','keyword','erdoÄŸan','merkel','modi','bjp','cdp','akp','hÃ¼kÃ¼met','gsyä°h',\n",
    "                'government','govt','regierung','wirtschaft','ekonomi','keyword','जी','है।','है,','ji','shri','ji.','जी','हैं।','pm',\n",
    "                'india’s','day','जी।','बहुत-बहुत','हर','लोगों','rt']\n",
    "\n",
    "stop_words=list(stopwords_english)+list(stopwords_deutsch)+list(stopwords_turkish)+stopwords_hindi+more_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now load the csv which contains tweets on various keywords from 12 locations in 3 countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df=pd.read_csv('.\\data\\dataset.csv',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20298</th>\n",
       "      <td>@nan59232397\\n@Pervinsenem1\\n \\nAkp çıkana kad...</td>\n",
       "      <td>2/1/2021 11:58</td>\n",
       "      <td>Izmir</td>\n",
       "      <td>AKP</td>\n",
       "      <td>Government</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22757</th>\n",
       "      <td>Bu ülkede normal olan herhangi birşey var mı??...</td>\n",
       "      <td>3/1/2021 10:24</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>ekonomi</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27336</th>\n",
       "      <td>My mum (90 in March) got her first COVID vacci...</td>\n",
       "      <td>1/19/2021 18:49</td>\n",
       "      <td>Cologne</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>Vaccine</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets        Timestamp  \\\n",
       "20298  @nan59232397\\n@Pervinsenem1\\n \\nAkp çıkana kad...   2/1/2021 11:58   \n",
       "22757  Bu ülkede normal olan herhangi birşey var mı??...   3/1/2021 10:24   \n",
       "27336  My mum (90 in March) got her first COVID vacci...  1/19/2021 18:49   \n",
       "\n",
       "      Location  Keyword    Category  Country  \n",
       "20298    Izmir      AKP  Government   Turkey  \n",
       "22757  Antalya  ekonomi     Economy   Turkey  \n",
       "27336  Cologne  vaccine     Vaccine  Germany  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Since our dataframe does not have a column for country, we will define a function to add a new column \"country\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tweets       object\n",
       "Timestamp    object\n",
       "Location     object\n",
       "Keyword      object\n",
       "Category     object\n",
       "Country      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now tokenize the words in tweets using nltk.tokenize() method\n",
    "\n",
    "Only words that are not in stopwords listed defined earlier will be included.\n",
    "\n",
    "Also, the words will be converted to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenize =lambda x: [word.lower() for word in x.split() if word.lower() not in stop_words and \n",
    "                     word.startswith('@')==False and word.startswith('https')==False and word.isdigit()==False] \n",
    "\n",
    "\n",
    "df['Word_Tokens']=df['Tweets'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17899</th>\n",
       "      <td>இளைஞர்கள் அரசியலில் நுழைய வேண்டும் - பிரதமர் ம...</td>\n",
       "      <td>12/1/2021 9:29</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>BJP</td>\n",
       "      <td>Government</td>\n",
       "      <td>India</td>\n",
       "      <td>[இளைஞர்கள், அரசியலில், நுழைய, வேண்டும், -, பிர...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Die Antwort auf die Frage nach dem #homeoffice...</td>\n",
       "      <td>5/1/2021 18:25</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Merkel</td>\n",
       "      <td>Angela Merkel</td>\n",
       "      <td>Germany</td>\n",
       "      <td>[antwort, frage, #homeoffice, zeigt, schön, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13384</th>\n",
       "      <td>https://t.co/aOA5wys1iw https://t.co/uAhAtyCa5O</td>\n",
       "      <td>30-12-2020 16:00</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>economy</td>\n",
       "      <td>Economy</td>\n",
       "      <td>India</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27934</th>\n",
       "      <td>In Berlin stehen in unterschiedlichen Impfzent...</td>\n",
       "      <td>1/18/2021 17:00</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Pfizer-Biontech</td>\n",
       "      <td>Vaccine</td>\n",
       "      <td>Germany</td>\n",
       "      <td>[berlin, stehen, unterschiedlichen, impfzentre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12669</th>\n",
       "      <td>इकॉनमी के लिए खुशखबरी ला रहे हैं ये आंकड़े..\\n...</td>\n",
       "      <td>4/1/2021 4:50</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>economy</td>\n",
       "      <td>Economy</td>\n",
       "      <td>India</td>\n",
       "      <td>[इकॉनमी, खुशखबरी, ला, आंकड़े..]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets         Timestamp  \\\n",
       "17899  இளைஞர்கள் அரசியலில் நுழைய வேண்டும் - பிரதமர் ம...    12/1/2021 9:29   \n",
       "130    Die Antwort auf die Frage nach dem #homeoffice...    5/1/2021 18:25   \n",
       "13384    https://t.co/aOA5wys1iw https://t.co/uAhAtyCa5O  30-12-2020 16:00   \n",
       "27934  In Berlin stehen in unterschiedlichen Impfzent...   1/18/2021 17:00   \n",
       "12669  इकॉनमी के लिए खुशखबरी ला रहे हैं ये आंकड़े..\\n...     4/1/2021 4:50   \n",
       "\n",
       "      Location          Keyword       Category  Country  \\\n",
       "17899  Chennai              BJP     Government    India   \n",
       "130     Berlin           Merkel  Angela Merkel  Germany   \n",
       "13384  Chennai          economy        Economy    India   \n",
       "27934  Hamburg  Pfizer-Biontech        Vaccine  Germany   \n",
       "12669    Delhi          economy        Economy    India   \n",
       "\n",
       "                                             Word_Tokens  \n",
       "17899  [இளைஞர்கள், அரசியலில், நுழைய, வேண்டும், -, பிர...  \n",
       "130    [antwort, frage, #homeoffice, zeigt, schön, po...  \n",
       "13384                                                 []  \n",
       "27934  [berlin, stehen, unterschiedlichen, impfzentre...  \n",
       "12669                    [इकॉनमी, खुशखबरी, ला, आंकड़े..]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now define another function to clean the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to remove noise\n",
    "\n",
    "def clean_text(text_list):\n",
    "    for text in text_list:\n",
    "        text = re.sub(r'@[a-zA-Z0-9_]+','',text)\n",
    "        text = re.sub(r'#','',text)\n",
    "        text = re.sub(r'rt[\\s]+','',text)\n",
    "        text = re.sub(r'https?:\\/\\/\\s+','',text)\n",
    "        text = re.sub(r'timestamp|keyword|tweets|geocode|modi|merkel|erdogan|tayyip','',text)\n",
    "        text = re.sub('\\[.*?\\]', '', text)\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)\n",
    "        text = re.sub('[‘’“”…]', '', text)\n",
    "        text = re.sub('@', '', text)\n",
    "        text = re.sub(',', '', text)\n",
    "        text = re.sub(':', '', text)\n",
    "#     translator = google_translator()\n",
    "#     text=translator.translate(text,lang_tgt='en')\n",
    "    \n",
    "    \n",
    "    return text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word_Tokens']=df['Word_Tokens'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31286</th>\n",
       "      <td>@mehmettt6006 Faz3 ara sonucu açıklanacak Türk...</td>\n",
       "      <td>1/21/2021 7:41</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Pfizer-Biontech</td>\n",
       "      <td>Vaccine</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>[faz3, ara, sonucu, açıklanacak, türkiye, kolu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29240</th>\n",
       "      <td>@AroonTripathi @APS588 Suspect vaccine</td>\n",
       "      <td>1/20/2021 17:27</td>\n",
       "      <td>Chennai</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>Vaccine</td>\n",
       "      <td>India</td>\n",
       "      <td>[suspect, vaccine]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>Will The Effects of COVID-19 Continue to Influ...</td>\n",
       "      <td>31-12-2020 13:57</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>covid</td>\n",
       "      <td>Public confidence in government's handling of ...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>[effects, covid-19, continue, influence, consu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19198</th>\n",
       "      <td>Emine Erdoğan'ın sahiplendiği leblebinin bende...</td>\n",
       "      <td>29-12-2020 11:37</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>Erdoğan</td>\n",
       "      <td>Recep Tayyip Erdo?an</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>[emine, erdoğan'ın, sahiplendiği, leblebinin, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets         Timestamp  \\\n",
       "31286  @mehmettt6006 Faz3 ara sonucu açıklanacak Türk...    1/21/2021 7:41   \n",
       "29240             @AroonTripathi @APS588 Suspect vaccine   1/20/2021 17:27   \n",
       "8732   Will The Effects of COVID-19 Continue to Influ...  31-12-2020 13:57   \n",
       "19198  Emine Erdoğan'ın sahiplendiği leblebinin bende...  29-12-2020 11:37   \n",
       "\n",
       "      Location          Keyword  \\\n",
       "31286   Ankara  Pfizer-Biontech   \n",
       "29240  Chennai          vaccine   \n",
       "8732   Hamburg            covid   \n",
       "19198  Antalya          Erdoğan   \n",
       "\n",
       "                                                Category  Country  \\\n",
       "31286                                            Vaccine   Turkey   \n",
       "29240                                            Vaccine    India   \n",
       "8732   Public confidence in government's handling of ...  Germany   \n",
       "19198                               Recep Tayyip Erdo?an   Turkey   \n",
       "\n",
       "                                             Word_Tokens  \n",
       "31286  [faz3, ara, sonucu, açıklanacak, türkiye, kolu...  \n",
       "29240                                 [suspect, vaccine]  \n",
       "8732   [effects, covid-19, continue, influence, consu...  \n",
       "19198  [emine, erdoğan'ın, sahiplendiği, leblebinin, ...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Word_Tokens']=df['Word_Tokens'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24029</th>\n",
       "      <td>Anger as Mexico's Covid-19 czar makes beach tr...</td>\n",
       "      <td>5/1/2021 0:40</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>covid</td>\n",
       "      <td>Public confidence in government's handling of ...</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>anger mexico's covid-19 czar makes beach trip ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30947</th>\n",
       "      <td>Greece will not require tourists to provide ce...</td>\n",
       "      <td>1/15/2021 13:01</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>vaccine</td>\n",
       "      <td>Vaccine</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>greece require tourists provide certification ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17755</th>\n",
       "      <td>@BhavikaKapoor5 @AamAadmiParty @Kisanaktamorch...</td>\n",
       "      <td>12/1/2021 14:22</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>BJP</td>\n",
       "      <td>Government</td>\n",
       "      <td>India</td>\n",
       "      <td>spreading fake news dna congress. thugs have…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>@UlrichSchneider @Paritaet @DKSB_Bund @Tafel_D...</td>\n",
       "      <td>5/1/2021 18:41</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Regierung</td>\n",
       "      <td>Government</td>\n",
       "      <td>Germany</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets        Timestamp  \\\n",
       "24029  Anger as Mexico's Covid-19 czar makes beach tr...    5/1/2021 0:40   \n",
       "30947  Greece will not require tourists to provide ce...  1/15/2021 13:01   \n",
       "17755  @BhavikaKapoor5 @AamAadmiParty @Kisanaktamorch...  12/1/2021 14:22   \n",
       "1737   @UlrichSchneider @Paritaet @DKSB_Bund @Tafel_D...   5/1/2021 18:41   \n",
       "\n",
       "       Location    Keyword                                           Category  \\\n",
       "24029  Istanbul      covid  Public confidence in government's handling of ...   \n",
       "30947  Istanbul    vaccine                                            Vaccine   \n",
       "17755    Mumbai        BJP                                         Government   \n",
       "1737     Berlin  Regierung                                         Government   \n",
       "\n",
       "       Country                                        Word_Tokens  \n",
       "24029   Turkey  anger mexico's covid-19 czar makes beach trip ...  \n",
       "30947   Turkey  greece require tourists provide certification ...  \n",
       "17755    India      spreading fake news dna congress. thugs have…  \n",
       "1737   Germany                                                     "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#create separate dataframes for turkey, india and germany\n",
    "\n",
    "df_germany=df[df['Country']=='Germany']\n",
    "df_turkey=df[df['Country']=='Turkey']\n",
    "df_india=df[df['Country']=='India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21053</th>\n",
       "      <td>AKP'ye yakın bir gazetenin Aylin Sözer cinayet...</td>\n",
       "      <td>29-12-2020 15:07</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>AKP</td>\n",
       "      <td>Government</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>akp'ye yakın bir gazetenin aylin sözer cinayet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18608</th>\n",
       "      <td>Bu ulke #ERDOĞANLAŞAHLANIŞ yasadi bu bir gerce...</td>\n",
       "      <td>3/1/2021 17:46</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Erdoğan</td>\n",
       "      <td>Recep Tayyip Erdo?an</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>ulke #erdoğanlaşahlaniş yasadi bir gercek su d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets         Timestamp  \\\n",
       "21053  AKP'ye yakın bir gazetenin Aylin Sözer cinayet...  29-12-2020 15:07   \n",
       "18608  Bu ulke #ERDOĞANLAŞAHLANIŞ yasadi bu bir gerce...    3/1/2021 17:46   \n",
       "\n",
       "       Location  Keyword              Category Country  \\\n",
       "21053   Antalya      AKP            Government  Turkey   \n",
       "18608  Istanbul  Erdoğan  Recep Tayyip Erdo?an  Turkey   \n",
       "\n",
       "                                             Word_Tokens  \n",
       "21053  akp'ye yakın bir gazetenin aylin sözer cinayet...  \n",
       "18608  ulke #erdoğanlaşahlaniş yasadi bir gercek su d...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turkey.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-a06e0f13cb1e>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_turkey['sentiment']=df_turkey['Word_Tokens'].apply(sentiment_tr)\n",
      "<ipython-input-28-a06e0f13cb1e>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_turkey['score']=df_turkey['Word_Tokens'].apply(sentiment_score_tr)\n",
      "<ipython-input-28-a06e0f13cb1e>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_germany['sentiment']=df_germany['Word_Tokens'].apply(sentiment_gr)\n",
      "<ipython-input-28-a06e0f13cb1e>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_germany['score']=df_germany['Word_Tokens'].apply(sentiment_score_gr)\n",
      "<ipython-input-28-a06e0f13cb1e>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_india['sentiment']=df_india['Word_Tokens'].apply(sentiment_en)\n",
      "<ipython-input-28-a06e0f13cb1e>:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_india['score']=df_india['Word_Tokens'].apply(sentiment_score_en)\n"
     ]
    }
   ],
   "source": [
    "#add clolumns for sentiment and score for turkish, german and indian dataframe using the functions and models defined above\n",
    "df_turkey['sentiment']=df_turkey['Word_Tokens'].apply(sentiment_tr)\n",
    "df_turkey['score']=df_turkey['Word_Tokens'].apply(sentiment_score_tr)\n",
    "\n",
    "df_germany['sentiment']=df_germany['Word_Tokens'].apply(sentiment_gr)\n",
    "df_germany['score']=df_germany['Word_Tokens'].apply(sentiment_score_gr)\n",
    "\n",
    "df_india['sentiment']=df_india['Word_Tokens'].apply(sentiment_en)\n",
    "df_india['score']=df_india['Word_Tokens'].apply(sentiment_score_en)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Now we will define a function to add one more column to categorise tweets into various categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15446</th>\n",
       "      <td>Amidst these hard Corona time. There come a gr...</td>\n",
       "      <td>02-01-2021 09:02</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>corona</td>\n",
       "      <td>India</td>\n",
       "      <td>amidst hard time. come great relief pm.he decl...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.990540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14123</th>\n",
       "      <td>@NITINchirp @kmimicryartist @AnOpenLetter001 j...</td>\n",
       "      <td>02-01-2021 15:27</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>GDP</td>\n",
       "      <td>India</td>\n",
       "      <td>jab waha ka idiot president mask pehan se mana...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.947328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12534</th>\n",
       "      <td>Always supporting the economy, this company di...</td>\n",
       "      <td>04-01-2021 14:17</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>economy</td>\n",
       "      <td>India</td>\n",
       "      <td>supporting economy, company farmers reliance f...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.996716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets         Timestamp  \\\n",
       "15446  Amidst these hard Corona time. There come a gr...  02-01-2021 09:02   \n",
       "14123  @NITINchirp @kmimicryartist @AnOpenLetter001 j...  02-01-2021 15:27   \n",
       "12534  Always supporting the economy, this company di...  04-01-2021 14:17   \n",
       "\n",
       "      Location  Keyword country  \\\n",
       "15446  Kolkata   corona   India   \n",
       "14123   Mumbai      GDP   India   \n",
       "12534    Delhi  economy   India   \n",
       "\n",
       "                                             Word_Tokens sentiment     score  \n",
       "15446  amidst hard time. come great relief pm.he decl...  POSITIVE  0.990540  \n",
       "14123  jab waha ka idiot president mask pehan se mana...  NEGATIVE  0.947328  \n",
       "12534  supporting economy, company farmers reliance f...  POSITIVE  0.996716  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_india.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-159-051c68633ef3>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_india['Category']=df_india['Keyword'].apply(categories)\n",
      "<ipython-input-159-051c68633ef3>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_turkey['Category']=df_turkey['Keyword'].apply(categories)\n",
      "<ipython-input-159-051c68633ef3>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_germany['Category']=df_germany['Keyword'].apply(categories)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_india['Category']=df_india['Keyword'].apply(categories)\n",
    "df_turkey['Category']=df_turkey['Keyword'].apply(categories)\n",
    "df_germany['Category']=df_germany['Keyword'].apply(categories)\n",
    "\n",
    "# df_india.to_csv(\"Indien2021.csv\", encoding=\"utf-8\")\n",
    "# df_turkey.to_csv(\"turkiye2021.csv\", encoding=\"utf-8\")\n",
    "# df_germany.to_csv(\"germania2021.csv\", encoding=\"utf-8\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove columns with na values\n",
    "\n",
    "df_turkey = df_turkey[df_turkey[\"Location\"].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21367</th>\n",
       "      <td>@__stds__ @cibukadam @avukat_osman Canım arkad...</td>\n",
       "      <td>30-12-2020 07:43</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>hükümet</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>canım arkadaşım, özel sektör üst düzey yönetic...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.716583</td>\n",
       "      <td>hükümet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18585</th>\n",
       "      <td>#ERDOĞANLAŞAHLANIŞ #Türkiye \\nReis Akdeniz’e v...</td>\n",
       "      <td>03-01-2021 20:21</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Erdoğan</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>#erdoğanlaşahlaniş #türkiye reis akdeniz’e bat...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.812970</td>\n",
       "      <td>erdoğan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23649</th>\n",
       "      <td>6 Ocak 2021 Çarşamba günü Saat 12.00-12.45 Atü...</td>\n",
       "      <td>04-01-2021 09:51</td>\n",
       "      <td>Izmir</td>\n",
       "      <td>corona</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>ocak çarşamba günü saat 12.00-12.45 atürk tv &amp;...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.876716</td>\n",
       "      <td>Govt Handling Of Pandemic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets         Timestamp  \\\n",
       "21367  @__stds__ @cibukadam @avukat_osman Canım arkad...  30-12-2020 07:43   \n",
       "18585  #ERDOĞANLAŞAHLANIŞ #Türkiye \\nReis Akdeniz’e v...  03-01-2021 20:21   \n",
       "23649  6 Ocak 2021 Çarşamba günü Saat 12.00-12.45 Atü...  04-01-2021 09:51   \n",
       "\n",
       "       Location  Keyword country  \\\n",
       "21367  Istanbul  hükümet  Turkey   \n",
       "18585  Istanbul  Erdoğan  Turkey   \n",
       "23649     Izmir   corona  Turkey   \n",
       "\n",
       "                                             Word_Tokens sentiment     score  \\\n",
       "21367  canım arkadaşım, özel sektör üst düzey yönetic...  positive  0.716583   \n",
       "18585  #erdoğanlaşahlaniş #türkiye reis akdeniz’e bat...  positive  0.812970   \n",
       "23649  ocak çarşamba günü saat 12.00-12.45 atürk tv &...  positive  0.876716   \n",
       "\n",
       "                        Category  \n",
       "21367                    hükümet  \n",
       "18585                    erdoğan  \n",
       "23649  Govt Handling Of Pandemic  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_turkey.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-193-9422267af0f8>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_india['Category']=df_india['Category'].apply(categories)\n",
      "<ipython-input-193-9422267af0f8>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_turkey['Category']=df_turkey['Category'].apply(categories)\n",
      "<ipython-input-193-9422267af0f8>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_germany['Category']=df_germany['Category'].apply(categories)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_india['Category']=df_india['Category'].apply(categories)\n",
    "df_turkey['Category']=df_turkey['Category'].apply(categories)\n",
    "df_germany['Category']=df_germany['Category'].apply(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames=[df_germany,df_turkey,df_india]\n",
    "\n",
    "df=pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24896</th>\n",
       "      <td>Yav ben artık dayanamıyorum artık, bu hekimler...</td>\n",
       "      <td>3/1/2021 11:31</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>covid</td>\n",
       "      <td>Public confidence in government's handling of ...</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>yav dayanamıyorum artık, hekimlerin sağlık çal...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.946675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22217</th>\n",
       "      <td>2021'de trafik cezaları el yakacak https://t.c...</td>\n",
       "      <td>1/1/2021 9:35</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>ekonomi</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>2021'de trafik cezaları el yakacak</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.512002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13947</th>\n",
       "      <td>@INCIndia Aap hote to complete lockdown mei bh...</td>\n",
       "      <td>31-12-2020 11:19</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>GDP</td>\n",
       "      <td>Economy</td>\n",
       "      <td>India</td>\n",
       "      <td>aap hote complete lockdown mei bhi 100% growth...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.614318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8435</th>\n",
       "      <td>@NYGovCuomo SO in EASTERN EUROPE the ANTI FASC...</td>\n",
       "      <td>3/1/2021 22:23</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>covid</td>\n",
       "      <td>Public confidence in government's handling of ...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>eastern europe anti faschists politically mono...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.970511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3694</th>\n",
       "      <td>@MarleneJWeiss Ne. Und ich finde, es ist jetzt...</td>\n",
       "      <td>5/1/2021 10:48</td>\n",
       "      <td>Munich</td>\n",
       "      <td>Wirtschaft</td>\n",
       "      <td>Economy</td>\n",
       "      <td>Germany</td>\n",
       "      <td>ne. finde, echt zeit, (berufstätigen) eltern i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.975906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets         Timestamp  \\\n",
       "24896  Yav ben artık dayanamıyorum artık, bu hekimler...    3/1/2021 11:31   \n",
       "22217  2021'de trafik cezaları el yakacak https://t.c...     1/1/2021 9:35   \n",
       "13947  @INCIndia Aap hote to complete lockdown mei bh...  31-12-2020 11:19   \n",
       "8435   @NYGovCuomo SO in EASTERN EUROPE the ANTI FASC...    3/1/2021 22:23   \n",
       "3694   @MarleneJWeiss Ne. Und ich finde, es ist jetzt...    5/1/2021 10:48   \n",
       "\n",
       "       Location     Keyword  \\\n",
       "24896    Ankara       covid   \n",
       "22217  Istanbul     ekonomi   \n",
       "13947     Delhi         GDP   \n",
       "8435    Hamburg       covid   \n",
       "3694     Munich  Wirtschaft   \n",
       "\n",
       "                                                Category  Country  \\\n",
       "24896  Public confidence in government's handling of ...   Turkey   \n",
       "22217                                            Economy   Turkey   \n",
       "13947                                            Economy    India   \n",
       "8435   Public confidence in government's handling of ...  Germany   \n",
       "3694                                             Economy  Germany   \n",
       "\n",
       "                                             Word_Tokens sentiment     score  \n",
       "24896  yav dayanamıyorum artık, hekimlerin sağlık çal...  negative  0.946675  \n",
       "22217                 2021'de trafik cezaları el yakacak  positive  0.512002  \n",
       "13947  aap hote complete lockdown mei bhi 100% growth...  POSITIVE  0.614318  \n",
       "8435   eastern europe anti faschists politically mono...  negative  0.970511  \n",
       "3694   ne. finde, echt zeit, (berufstätigen) eltern i...  negative  0.975906  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment Score']=df['sentiment'].apply(lambda x: 1 if x.lower()==\"positive\" else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>Sentiment Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24041</th>\n",
       "      <td>Tacikistan'da 8 aydan bu yana ilk defa Covid-1...</td>\n",
       "      <td>4/1/2021 23:00</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>covid</td>\n",
       "      <td>Public confidence in government's handling of ...</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>tacikistan'da aydan yana covid-19 vakası sapta...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.939047</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21024</th>\n",
       "      <td>@arz_che @HergelePostasi Bak kardeşim.  Gerçek...</td>\n",
       "      <td>30-12-2020 00:32</td>\n",
       "      <td>Antalya</td>\n",
       "      <td>AKP</td>\n",
       "      <td>Government</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>bak kardeşim. gerçekten ciddi bir sorunumuz va...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.992583</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8652</th>\n",
       "      <td>@MrJonasDanner Kannte bis zum 30.12. auch niem...</td>\n",
       "      <td>1/1/2021 15:01</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>covid</td>\n",
       "      <td>Public confidence in government's handling of ...</td>\n",
       "      <td>Germany</td>\n",
       "      <td>kannte 30.12. niemanden. cousine gestorben. al...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.935748</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets         Timestamp  \\\n",
       "24041  Tacikistan'da 8 aydan bu yana ilk defa Covid-1...    4/1/2021 23:00   \n",
       "21024  @arz_che @HergelePostasi Bak kardeşim.  Gerçek...  30-12-2020 00:32   \n",
       "8652   @MrJonasDanner Kannte bis zum 30.12. auch niem...    1/1/2021 15:01   \n",
       "\n",
       "       Location Keyword                                           Category  \\\n",
       "24041  Istanbul   covid  Public confidence in government's handling of ...   \n",
       "21024   Antalya     AKP                                         Government   \n",
       "8652    Hamburg   covid  Public confidence in government's handling of ...   \n",
       "\n",
       "       Country                                        Word_Tokens sentiment  \\\n",
       "24041   Turkey  tacikistan'da aydan yana covid-19 vakası sapta...  negative   \n",
       "21024   Turkey  bak kardeşim. gerçekten ciddi bir sorunumuz va...  negative   \n",
       "8652   Germany  kannte 30.12. niemanden. cousine gestorben. al...  negative   \n",
       "\n",
       "          score  Sentiment Score  \n",
       "24041  0.939047               -1  \n",
       "21024  0.992583               -1  \n",
       "8652   0.935748               -1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sentiment Score']=df['Sentiment Score']*df['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Positive']=df['sentiment'].apply(lambda x: 1 if x.lower()=='positive'else 0)\n",
    "\n",
    "df['Positive']=df['Positive']*df['score']\n",
    "\n",
    "df['Negative']=df['sentiment'].apply(lambda x: 1 if x.lower()=='negative'else 0)\n",
    "\n",
    "df['Negative']=df['Negative']*df['score']\n",
    "\n",
    "df['sentiment']=df['sentiment'].apply(lambda x: x.upper())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Location</th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Category</th>\n",
       "      <th>Country</th>\n",
       "      <th>Word_Tokens</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>score</th>\n",
       "      <th>Sentiment Score</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9404</th>\n",
       "      <td>Was gut für Europa ist, ist gut für uns: Angel...</td>\n",
       "      <td>6/1/2021 20:09</td>\n",
       "      <td>Munich</td>\n",
       "      <td>Merkel</td>\n",
       "      <td>Angela Merkel</td>\n",
       "      <td>Germany</td>\n",
       "      <td>europa ist, uns: angela betreibt ausverkauf de...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.999931</td>\n",
       "      <td>-0.999931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2951</th>\n",
       "      <td>https://t.co/H0gHwucwt1\\n\\nDa gehen sie hin un...</td>\n",
       "      <td>31-12-2020 10:25</td>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Regierung</td>\n",
       "      <td>Government</td>\n",
       "      <td>Germany</td>\n",
       "      <td>gelder, wohnung sehen kann, entwed…</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>0.977776</td>\n",
       "      <td>-0.977776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>@me_locket These words reminds me of modi rule...</td>\n",
       "      <td>4/1/2021 10:54</td>\n",
       "      <td>Kolkata</td>\n",
       "      <td>Modi</td>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>India</td>\n",
       "      <td>words reminds rule india</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.997276</td>\n",
       "      <td>0.997276</td>\n",
       "      <td>0.997276</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18518</th>\n",
       "      <td>Erdoğan'ın başörtüsü sorunu - Medyascope\\nBugü...</td>\n",
       "      <td>4/1/2021 9:26</td>\n",
       "      <td>Istanbul</td>\n",
       "      <td>Erdoğan</td>\n",
       "      <td>Recep Tayyip Erdo?an</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>erdoğan'ın başörtüsü sorunu - medyascope bugün...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.879537</td>\n",
       "      <td>-0.879537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.879537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets         Timestamp  \\\n",
       "9404   Was gut für Europa ist, ist gut für uns: Angel...    6/1/2021 20:09   \n",
       "2951   https://t.co/H0gHwucwt1\\n\\nDa gehen sie hin un...  31-12-2020 10:25   \n",
       "10236  @me_locket These words reminds me of modi rule...    4/1/2021 10:54   \n",
       "18518  Erdoğan'ın başörtüsü sorunu - Medyascope\\nBugü...     4/1/2021 9:26   \n",
       "\n",
       "       Location    Keyword              Category  Country  \\\n",
       "9404     Munich     Merkel         Angela Merkel  Germany   \n",
       "2951    Hamburg  Regierung            Government  Germany   \n",
       "10236   Kolkata       Modi         Narendra Modi    India   \n",
       "18518  Istanbul    Erdoğan  Recep Tayyip Erdo?an   Turkey   \n",
       "\n",
       "                                             Word_Tokens sentiment     score  \\\n",
       "9404   europa ist, uns: angela betreibt ausverkauf de...   NEUTRAL  0.999931   \n",
       "2951                 gelder, wohnung sehen kann, entwed…   NEUTRAL  0.977776   \n",
       "10236                           words reminds rule india  POSITIVE  0.997276   \n",
       "18518  erdoğan'ın başörtüsü sorunu - medyascope bugün...  NEGATIVE  0.879537   \n",
       "\n",
       "       Sentiment Score  Positive  Negative  \n",
       "9404         -0.999931  0.000000  0.000000  \n",
       "2951         -0.977776  0.000000  0.000000  \n",
       "10236         0.997276  0.997276  0.000000  \n",
       "18518        -0.879537  0.000000  0.879537  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_germany=df[df['Country']=='Germany']\n",
    "df_turkey=df[df['Country']=='Turkey']\n",
    "df_india=df[df['Country']=='India']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the dataframes which contain sentiment and scores as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_germany.to_csv('.\\data\\germany.csv',encoding='utf-8')\n",
    "\n",
    "df_india.to_csv('.\\data\\india.csv',encoding='utf-8')\n",
    "\n",
    "df_turkey.to_csv('.\\data\\Turkey.csv', encoding='utf-8')\n",
    "\n",
    "df.to_csv('.\\data\\Final.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_germany=df[df['Country']=='Germany']\n",
    "df_turkey=df[df['Country']=='Turkey']\n",
    "df_india=df[df['Country']=='India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x00000241C474ED60>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_india.groupby(['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'turkey']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" I love turkey\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func =lambda x: x fot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
